{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61efe0ce-5a3c-4a90-a9a8-5f954317c4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:50:33.522413Z",
     "iopub.status.busy": "2023-07-10T18:50:33.521927Z",
     "iopub.status.idle": "2023-07-10T18:50:33.524976Z",
     "shell.execute_reply": "2023-07-10T18:50:33.524489Z",
     "shell.execute_reply.started": "2023-07-10T18:50:33.522390Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install easydict\n",
    "# !pip install tensorboardX\n",
    "# !pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2855470a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:50.958003Z",
     "iopub.status.busy": "2023-07-14T14:36:50.957654Z",
     "iopub.status.idle": "2023-07-14T14:36:53.520420Z",
     "shell.execute_reply": "2023-07-14T14:36:53.519568Z",
     "shell.execute_reply.started": "2023-07-14T14:36:50.957972Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torchvision.models.resnet as resnet\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.optim import lr_scheduler\n",
    "from util.shedule import FixLR\n",
    "\n",
    "from dataset.total_text import TotalText\n",
    "from dataset.synth_text import SynthText\n",
    "\n",
    "from util.augmentation import BaseTransform, Augmentation\n",
    "from util.config import config as cfg, update_config, print_config\n",
    "from util.misc import AverageMeter\n",
    "from util.misc import mkdirs, to_device\n",
    "from util.option import BaseOptions\n",
    "from util.visualize import visualize_network_output\n",
    "from util.summary import LogSummary\n",
    "\n",
    "from easydict import EasyDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (function expandTensors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6caecaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:53.526924Z",
     "iopub.status.busy": "2023-07-14T14:36:53.526649Z",
     "iopub.status.idle": "2023-07-14T14:36:53.531947Z",
     "shell.execute_reply": "2023-07-14T14:36:53.531055Z",
     "shell.execute_reply.started": "2023-07-14T14:36:53.526883Z"
    }
   },
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e2de38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:53.533491Z",
     "iopub.status.busy": "2023-07-14T14:36:53.533404Z",
     "iopub.status.idle": "2023-07-14T14:36:58.878890Z",
     "shell.execute_reply": "2023-07-14T14:36:58.877745Z",
     "shell.execute_reply.started": "2023-07-14T14:36:53.533404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 256, 256])\n",
      "torch.Size([4, 128, 128, 128])\n",
      "torch.Size([4, 256, 64, 64])\n",
      "torch.Size([4, 512, 32, 32])\n",
      "torch.Size([4, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrain=True):\n",
    "        super().__init__()\n",
    "        net = VGG(make_layers(cfg['D']), init_weights=False)\n",
    "        if pretrain:\n",
    "            net.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "\n",
    "        self.stage1 = nn.Sequential(*[net.features[layer] for layer in range(0, 5)])\n",
    "        self.stage2 = nn.Sequential(*[net.features[layer] for layer in range(5, 10)])\n",
    "        self.stage3 = nn.Sequential(*[net.features[layer] for layer in range(10, 17)])\n",
    "        self.stage4 = nn.Sequential(*[net.features[layer] for layer in range(17, 24)])\n",
    "        self.stage5 = nn.Sequential(*[net.features[layer] for layer in range(24, 31)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.stage1(x)\n",
    "        C2 = self.stage2(C1)\n",
    "        C3 = self.stage3(C2)\n",
    "        C4 = self.stage4(C3)\n",
    "        C5 = self.stage5(C4)\n",
    "        return C1, C2, C3, C4, C5\n",
    "\n",
    "\n",
    "input = torch.randn((4, 3, 512, 512))\n",
    "net = VGG16()\n",
    "C1, C2, C3, C4, C5 = net(input)\n",
    "print(C1.size())\n",
    "print(C2.size())\n",
    "print(C3.size())\n",
    "print(C4.size())\n",
    "print(C5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e747a6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:58.881844Z",
     "iopub.status.busy": "2023-07-14T14:36:58.881585Z",
     "iopub.status.idle": "2023-07-14T14:36:58.890953Z",
     "shell.execute_reply": "2023-07-14T14:36:58.889248Z",
     "shell.execute_reply.started": "2023-07-14T14:36:58.881818Z"
    }
   },
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, upsampled, shortcut):\n",
    "        # print(\"Upsampled shape:\", upsampled.shape) # Print the shape of upsampled tensor\n",
    "        # print(\"Shortcut shape:\", shortcut.shape)\n",
    "        x = torch.cat([upsampled, shortcut], dim=1)\n",
    "        x = self.conv1x1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3x3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5e4c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:58.893665Z",
     "iopub.status.busy": "2023-07-14T14:36:58.892692Z",
     "iopub.status.idle": "2023-07-14T14:36:58.904309Z",
     "shell.execute_reply": "2023-07-14T14:36:58.903334Z",
     "shell.execute_reply.started": "2023-07-14T14:36:58.893665Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextNet(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone='vgg', output_channel=7, is_training=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_training = is_training\n",
    "        self.backbone_name = backbone\n",
    "        self.output_channel = output_channel\n",
    "        \n",
    "        if backbone == 'vgg':\n",
    "            \n",
    "            self.backbone = VGG16(pretrain=self.is_training)\n",
    "\n",
    "            self.deconv5 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "            self.merge4 = Upsample(512 + 256, 128)\n",
    "            self.merge3 = Upsample(256 + 128, 64)\n",
    "            self.merge2 = Upsample(128 + 64, 32)\n",
    "            self.merge1 = Upsample(64 + 32, 16)\n",
    "\n",
    "            self.predict = nn.Sequential(\n",
    "                nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(16, self.output_channel, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1, C2, C3, C4, C5 = self.backbone(x)\n",
    "        up5 = self.deconv5(C5)\n",
    "        up5 = F.relu(up5)\n",
    "\n",
    "        up4 = self.merge4(C4, up5)\n",
    "        up4 = F.relu(up4)\n",
    "\n",
    "        up3 = self.merge3(C3, up4)\n",
    "        up3 = F.relu(up3)\n",
    "\n",
    "        up2 = self.merge2(C2, up3)\n",
    "        up2 = F.relu(up2)\n",
    "\n",
    "        up1 = self.merge1(C1, up2)\n",
    "        output = self.predict(up1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "#     def load_model(self, model_path):\n",
    "#         print('Loading from {}'.format(model_path))\n",
    "#         state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "#         self.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4933a073-38d5-4b5a-8b1c-5a3f3c32c86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:36:58.905077Z",
     "iopub.status.busy": "2023-07-14T14:36:58.904833Z",
     "iopub.status.idle": "2023-07-14T14:37:04.115061Z",
     "shell.execute_reply": "2023-07-14T14:37:04.113783Z",
     "shell.execute_reply.started": "2023-07-14T14:36:58.905077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 256, 256])\n",
      "torch.Size([4, 128, 128, 128])\n",
      "torch.Size([4, 256, 64, 64])\n",
      "torch.Size([4, 512, 32, 32])\n",
      "torch.Size([4, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((4, 3, 512, 512))\n",
    "net = VGG16()\n",
    "C1, C2, C3, C4, C5 = net(input)\n",
    "print(C1.size())\n",
    "print(C2.size())\n",
    "print(C3.size())\n",
    "print(C4.size())\n",
    "print(C5.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02783a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:04.116593Z",
     "iopub.status.busy": "2023-07-14T14:37:04.116332Z",
     "iopub.status.idle": "2023-07-14T14:37:10.733467Z",
     "shell.execute_reply": "2023-07-14T14:37:10.732095Z",
     "shell.execute_reply.started": "2023-07-14T14:37:04.116562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((4, 3, 512, 512))\n",
    "net = TextNet().cuda()\n",
    "output = net(input.cuda())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61317214-6517-48f4-ada8-9d518724eaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.735152Z",
     "iopub.status.busy": "2023-07-14T14:37:10.734706Z",
     "iopub.status.idle": "2023-07-14T14:37:10.751117Z",
     "shell.execute_reply": "2023-07-14T14:37:10.750080Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.735152Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def ohem(self, predict, target, train_mask, negative_ratio=3.):\n",
    "        pos = (target * train_mask).bool()\n",
    "        neg = ((1 - target) * train_mask).bool()\n",
    "\n",
    "        n_pos = pos.float().sum()\n",
    "\n",
    "        if n_pos.item() > 0:\n",
    "            # loss_pos = F.cross_entropy(predict[pos.view(-1, 1)], target[pos], reduction='sum')\n",
    "            # loss_neg = F.cross_entropy(predict[neg.view(-1, 1)], target[neg], reduction='none')\n",
    "            \n",
    "            loss_pos = F.cross_entropy(predict[pos], target[pos], reduction='sum')\n",
    "            loss_neg = F.cross_entropy(predict[neg], target[neg], reduction='none')\n",
    "\n",
    "            ###########\n",
    "            \n",
    "            n_neg = min(int(neg.float().sum().item()), int(negative_ratio * n_pos.float()))\n",
    "        else:\n",
    "            # loss_pos = 0.\n",
    "            # loss_neg = F.cross_entropy(predict[neg.view(-1, 1)], target[neg], reduction='none')\n",
    "            \n",
    "            loss_pos = torch.tensor(0.).to(predict.device)\n",
    "            loss_neg = F.cross_entropy(predict[neg], target[neg].long(), reduction='none')\n",
    "            \n",
    "            n_neg = 100\n",
    "        loss_neg, _ = torch.topk(loss_neg, n_neg)\n",
    "\n",
    "        return (loss_pos + loss_neg.sum()) / (n_pos + n_neg).float()\n",
    "\n",
    "    def forward(self, input, tr_mask, tcl_mask, sin_map, cos_map, radii_map, train_mask):\n",
    "        tr_pred = input[:, :2].permute(0, 2, 3, 1).contiguous().view(-1, 2)\n",
    "        tcl_pred = input[:, 2:4].permute(0, 2, 3, 1).contiguous().view(-1, 2)\n",
    "        sin_pred = input[:, 4].contiguous().view(-1)\n",
    "        cos_pred = input[:, 5].contiguous().view(-1)\n",
    "\n",
    "        scale = torch.sqrt(1.0 / (sin_pred ** 2 + cos_pred ** 2))\n",
    "        sin_pred = sin_pred * scale\n",
    "        cos_pred = cos_pred * scale\n",
    "\n",
    "        radii_pred = input[:, 6].contiguous().view(-1)\n",
    "\n",
    "        batch_size = tr_pred.size(0)\n",
    "        height, width = tr_mask.size(-2), tr_mask.size(-1)\n",
    "\n",
    "        train_mask = train_mask.view(-1)\n",
    "        tr_mask = tr_mask.view(-1)\n",
    "        tcl_mask = tcl_mask.view(-1)\n",
    "        sin_map = sin_map.view(-1)\n",
    "        cos_map = cos_map.view(-1)\n",
    "        radii_map = radii_map.view(-1)\n",
    "\n",
    "        # loss_tr = self.ohem(tr_pred, tr_mask.long(), train_mask.long())\n",
    "        loss_tr = self.ohem(tr_pred, tr_mask, train_mask)\n",
    "        \n",
    "\n",
    "        loss_tcl = 0.\n",
    "        tr_train_mask = train_mask * tr_mask\n",
    "        if tr_train_mask.sum().item() > 0:\n",
    "            loss_tcl = F.cross_entropy(tcl_pred[tr_train_mask], tcl_mask[tr_train_mask].long())\n",
    "\n",
    "        # geometry losses\n",
    "        loss_radii, loss_sin, loss_cos = 0., 0., 0.\n",
    "        tcl_train_mask = train_mask * tcl_mask\n",
    "        if tcl_train_mask.sum().item() > 0:\n",
    "            ones = radii_map.new(radii_pred[tcl_train_mask].size()).fill_(1.).float()\n",
    "            loss_radii = F.smooth_l1_loss(radii_pred[tcl_train_mask] / radii_map[tcl_train_mask], ones)\n",
    "            loss_sin = F.smooth_l1_loss(sin_pred[tcl_train_mask], sin_map[tcl_train_mask])\n",
    "            loss_cos = F.smooth_l1_loss(cos_pred[tcl_train_mask], cos_map[tcl_train_mask])\n",
    "\n",
    "        return loss_tr, loss_tcl, loss_radii, loss_sin, loss_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc06c122-ee5a-4855-a465-0445efaf2d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.752474Z",
     "iopub.status.busy": "2023-07-14T14:37:10.752157Z",
     "iopub.status.idle": "2023-07-14T14:37:10.759443Z",
     "shell.execute_reply": "2023-07-14T14:37:10.758248Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.752474Z"
    }
   },
   "outputs": [],
   "source": [
    "lr=None\n",
    "train_step=0\n",
    "\n",
    "def save_model(model, epoch, lr, optimzer):\n",
    "\n",
    "    save_dir = os.path.join(cfg['save_dir'], cfg['exp_name'])\n",
    "    if not os.path.exists(save_dir):\n",
    "        mkdirs(save_dir)\n",
    "\n",
    "    save_path = os.path.join(save_dir, 'textsnake_{}_{}.pth'.format(model.backbone_name, epoch))\n",
    "    print('Saving to {}.'.format(save_path))\n",
    "    state_dict = {\n",
    "        'lr': lr,\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict() if not cfg['mgpu'] else model.module.state_dict(),\n",
    "        'optimizer': optimzer.state_dict()\n",
    "    }\n",
    "    torch.save(state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bc52c6-9ad5-4a3d-9e79-c99ffe70fb2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.760995Z",
     "iopub.status.busy": "2023-07-14T14:37:10.760734Z",
     "iopub.status.idle": "2023-07-14T14:37:10.766953Z",
     "shell.execute_reply": "2023-07-14T14:37:10.765565Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.760857Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    print('Loading from {}'.format(model_path))\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf083f2-1756-4ea7-a5c5-43184c85bed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.769991Z",
     "iopub.status.busy": "2023-07-14T14:37:10.769728Z",
     "iopub.status.idle": "2023-07-14T14:37:10.775187Z",
     "shell.execute_reply": "2023-07-14T14:37:10.774283Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.769991Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Training and Validation Losses\")\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9941ca3-9e9b-4512-8aac-8c46cb4e4f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.777050Z",
     "iopub.status.busy": "2023-07-14T14:37:10.776779Z",
     "iopub.status.idle": "2023-07-14T14:37:10.789473Z",
     "shell.execute_reply": "2023-07-14T14:37:10.788719Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.777050Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, scheduler, optimizer, epoch, logger):\n",
    "\n",
    "    global train_step\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Epoch: {} : LR = {}'.format(epoch, lr))\n",
    "\n",
    "    for i, (img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map, meta) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "        img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map = to_device(\n",
    "            img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map)\n",
    "        \n",
    "        output = model(img)\n",
    "        tr_loss, tcl_loss, sin_loss, cos_loss, radii_loss = \\\n",
    "            criterion(output, tr_mask, tcl_mask, sin_map, cos_map, radius_map, train_mask)\n",
    "        loss = tr_loss + tcl_loss + sin_loss + cos_loss + radii_loss\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if cfg['viz'] and i % cfg['viz_freq'] == 0:\n",
    "            visualize_network_output(output, tr_mask, tcl_mask, mode='train')\n",
    "\n",
    "        if i % cfg['display_freq'] == 0:\n",
    "            print('({:d} / {:d}) - Loss: {:.4f} - tr_loss: {:.4f} - tcl_loss: {:.4f} - sin_loss: {:.4f} - cos_loss: {:.4f} - radii_loss: {:.4f}'.format(\n",
    "                i, len(train_loader), loss.item(), tr_loss.item(), tcl_loss.item(), sin_loss.item(), cos_loss.item(), radii_loss.item())\n",
    "            )\n",
    "\n",
    "        if i % cfg['log_freq'] == 0:\n",
    "            logger.write_scalars({\n",
    "                'loss': loss.item(),\n",
    "                'tr_loss': tr_loss.item(),\n",
    "                'tcl_loss': tcl_loss.item(),\n",
    "                'sin_loss': sin_loss.item(),\n",
    "                'cos_loss': cos_loss.item(),\n",
    "                'radii_loss': radii_loss.item()\n",
    "            }, tag='train', n_iter=train_step)\n",
    "\n",
    "    if epoch % cfg['save_freq'] == 0:\n",
    "        save_model(model, epoch, scheduler.get_lr(), optimizer)\n",
    "\n",
    "    print('Training Loss: {}'.format(losses.avg))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c03534-7e0b-41ad-8746-88d44a1db7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.791735Z",
     "iopub.status.busy": "2023-07-14T14:37:10.791429Z",
     "iopub.status.idle": "2023-07-14T14:37:10.803185Z",
     "shell.execute_reply": "2023-07-14T14:37:10.802169Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.791735Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(model, valid_loader, criterion, epoch, logger):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        losses = AverageMeter()\n",
    "        tr_losses = AverageMeter()\n",
    "        tcl_losses = AverageMeter()\n",
    "        sin_losses = AverageMeter()\n",
    "        cos_losses = AverageMeter()\n",
    "        radii_losses = AverageMeter()\n",
    "\n",
    "        for i, (img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map, meta) in enumerate(valid_loader):\n",
    "\n",
    "            img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map = to_device(\n",
    "                img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map)\n",
    "            \n",
    "            output = model(img)\n",
    "\n",
    "            tr_loss, tcl_loss, sin_loss, cos_loss, radii_loss = \\\n",
    "                criterion(output, tr_mask, tcl_mask, sin_map, cos_map, radius_map, train_mask)\n",
    "            loss = tr_loss + tcl_loss + sin_loss + cos_loss + radii_loss\n",
    "\n",
    "            # update losses\n",
    "            losses.update(loss.item())\n",
    "            tr_losses.update(tr_loss.item())\n",
    "            tcl_losses.update(tcl_loss.item())\n",
    "            sin_losses.update(sin_loss.item())\n",
    "            cos_losses.update(cos_loss.item())\n",
    "            radii_losses.update(radii_loss.item())\n",
    "\n",
    "            if cfg['viz'] and i % cfg['viz_freq'] == 0:\n",
    "                visualize_network_output(output, tr_mask, tcl_mask, mode='val')\n",
    "\n",
    "            if i % cfg['display_freq'] == 0:\n",
    "                print(\n",
    "                    'Validation: - Loss: {:.4f} - tr_loss: {:.4f} - tcl_loss: {:.4f} - sin_loss: {:.4f} - cos_loss: {:.4f} - radii_loss: {:.4f}'.format(\n",
    "                        loss.item(), tr_loss.item(), tcl_loss.item(), sin_loss.item(),\n",
    "                        cos_loss.item(), radii_loss.item())\n",
    "                )\n",
    "\n",
    "        logger.write_scalars({\n",
    "            'loss': losses.avg,\n",
    "            'tr_loss': tr_losses.avg,\n",
    "            'tcl_loss': tcl_losses.avg,\n",
    "            'sin_loss': sin_losses.avg,\n",
    "            'cos_loss': cos_losses.avg,\n",
    "            'radii_loss': radii_losses.avg\n",
    "        }, tag='val', n_iter=epoch)\n",
    "\n",
    "        print('Validation Loss: {}'.format(losses.avg))\n",
    "        return losses.avg       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd3a8f5f-b1ad-4d4e-bcef-5d5603670b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:35:23.976368Z",
     "iopub.status.busy": "2023-07-14T14:35:23.975430Z",
     "iopub.status.idle": "2023-07-14T14:35:23.992474Z",
     "shell.execute_reply": "2023-07-14T14:35:23.991492Z",
     "shell.execute_reply.started": "2023-07-14T14:35:23.976324Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    if mp.get_start_method(allow_none=True) != 'spawn':\n",
    "        mp.set_start_method('spawn', force=True)\n",
    "        \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "        \n",
    "    global lr\n",
    "    print(cfg['dataset'])\n",
    "    #######\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if cfg['dataset'] == 'total-text':\n",
    "\n",
    "        trainset = TotalText(\n",
    "            data_root='data/total-text',\n",
    "            ignore_list=None,\n",
    "            is_training=True,\n",
    "            transform=Augmentation(size=cfg['input_size'], mean=cfg['means'], std=cfg['stds'])\n",
    "        )\n",
    "\n",
    "        valset = TotalText(\n",
    "            data_root='data/total-text',\n",
    "            ignore_list=None,\n",
    "            is_training=False,\n",
    "            transform=BaseTransform(size=cfg['input_size'], mean=cfg['means'], std=cfg['stds'])\n",
    "        )\n",
    "\n",
    "    elif cfg['dataset'] == 'synth-text':\n",
    "        trainset = SynthText(\n",
    "            data_root='data/SynthText',\n",
    "            is_training=True,\n",
    "            transform=Augmentation(size=cfg['input_size'], mean=cfg['means'], std=cfg['stds'])\n",
    "        )\n",
    "        valset = None\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    train_loader = data.DataLoader(trainset, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'])\n",
    "    if valset:\n",
    "        val_loader = data.DataLoader(valset, batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'])\n",
    "    else:\n",
    "        valset = None\n",
    "\n",
    "    log_dir = os.path.join(cfg['log_dir'], datetime.now().strftime('%b%d_%H-%M-%S_') + cfg['exp_name'])\n",
    "    logger = LogSummary(log_dir)\n",
    "\n",
    "    # Model\n",
    "    model = TextNet(is_training=True, backbone='vgg', output_channel=7)\n",
    "        \n",
    "    if cfg['mgpu']:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(cfg['device'])\n",
    "    # model = model.to(device)\n",
    "    \n",
    "    #print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    \n",
    "    if cfg['cuda']:\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if cfg['resume']:\n",
    "        load_model(model, cfg['resume'])\n",
    "\n",
    "    criterion = TextLoss()\n",
    "    lr = cfg['lr']\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "\n",
    "    if cfg['dataset'] == 'synth-text':\n",
    "        scheduler = FixLR(optimizer)\n",
    "    else:\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "    print('Start training TextSnake.')\n",
    "    \n",
    "    for epoch in range(cfg['start_epoch'], cfg['max_epoch']):\n",
    "        # train(model, train_loader, criterion, scheduler, optimizer, epoch, logger)\n",
    "        train_loss=train(model, train_loader, criterion, scheduler, optimizer, epoch, logger)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        if valset:\n",
    "            # validation(model, val_loader, criterion, epoch, logger)\n",
    "            val_loss=validation(model, val_loader, criterion, epoch, logger)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "    print('End.')\n",
    "    \n",
    "    plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff4b9f32-9004-4047-96ba-d1b0af97baa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T01:50:12.011098Z",
     "iopub.status.busy": "2023-07-11T01:50:12.010433Z",
     "iopub.status.idle": "2023-07-11T01:50:17.864075Z",
     "shell.execute_reply": "2023-07-11T01:50:17.862777Z",
     "shell.execute_reply.started": "2023-07-11T01:50:12.011068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total-text\n",
      "==========Options============\n",
      "A: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
      "B: [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
      "D: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
      "E: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
      "exp_name: vgg123456_78\n",
      "net: vgg\n",
      "dataset: total-text\n",
      "resume: None\n",
      "num_workers: 8\n",
      "cuda: True\n",
      "mgpu: False\n",
      "save_dir: ./save/\n",
      "vis_dir: ./vis/\n",
      "log_dir: ./logs/\n",
      "loss: CrossEntropyLoss\n",
      "input_channel: 1\n",
      "pretrain: False\n",
      "verbose: True\n",
      "viz: True\n",
      "start_iter: 0\n",
      "max_epoch: 201\n",
      "start_epoch: 0\n",
      "lr: 0.0001\n",
      "lr_adjust: fix\n",
      "stepvalues: []\n",
      "weight_decay: 0.0\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "batch_size: 8\n",
      "optim: SGD\n",
      "display_freq: 50\n",
      "viz_freq: 50\n",
      "save_freq: 50\n",
      "log_freq: 100\n",
      "val_freq: 100\n",
      "rescale: 255.0\n",
      "means: (0.485, 0.456, 0.406)\n",
      "stds: (0.229, 0.224, 0.225)\n",
      "input_size: 512\n",
      "checkepoch: -1\n",
      "img_root: None\n",
      "device: cuda\n",
      "=============End=============\n",
      "total-text\n",
      "Start training TextSnake.\n",
      "Epoch: 0 : LR = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "terminate called without an active exception\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f81de0fc310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 93056) is killed by signal: Aborted. \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m print_config(cfg)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# main\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [12], line 80\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart training TextSnake.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m], cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# train(model, train_loader, criterion, scheduler, optimizer, epoch, logger)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     train_loss\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valset:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# validation(model, val_loader, criterion, epoch, logger)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [10], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, scheduler, optimizer, epoch, logger)\u001b[0m\n\u001b[1;32m     17\u001b[0m train_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map \u001b[38;5;241m=\u001b[39m to_device(\n\u001b[1;32m     20\u001b[0m     img, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map)\n\u001b[0;32m---> 22\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m tr_loss, tcl_loss, sin_loss, cos_loss, radii_loss \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     24\u001b[0m     criterion(output, tr_mask, tcl_mask, sin_map, cos_map, radius_map, train_mask)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tcl_loss \u001b[38;5;241m+\u001b[39m sin_loss \u001b[38;5;241m+\u001b[39m cos_loss \u001b[38;5;241m+\u001b[39m radii_loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [5], line 27\u001b[0m, in \u001b[0;36mTextNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 27\u001b[0m     C1, C2, C3, C4, C5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     up5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeconv5(C5)\n\u001b[1;32m     29\u001b[0m     up5 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(up5)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [3], line 76\u001b[0m, in \u001b[0;36mVGG16.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 76\u001b[0m     C1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     C2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage2(C1)\n\u001b[1;32m     78\u001b[0m     C3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage3(C2)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "option = BaseOptions()\n",
    "command_line_args = [\"vgg123456_78\", \"--viz\", \"--net\", \"vgg\", \"--cuda\", \"True\", \"--dataset\", \"total-text\", \"--vis_dir\", \"./vis/\"]\n",
    "\n",
    "args = option.initialize(command_line_args)\n",
    "\n",
    "update_config(cfg, args)\n",
    "print_config(cfg)\n",
    "\n",
    "# main\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "834700cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:10.805588Z",
     "iopub.status.busy": "2023-07-14T14:37:10.805271Z",
     "iopub.status.idle": "2023-07-14T14:37:11.348156Z",
     "shell.execute_reply": "2023-07-14T14:37:11.347252Z",
     "shell.execute_reply.started": "2023-07-14T14:37:10.805588Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "import multiprocessing\n",
    "# from network.textnet import TextNet\n",
    "from util.detection import TextDetector\n",
    "# from util.augmentation import BaseTransform\n",
    "# from util.option import BaseOptions\n",
    "from util.visualize import visualize_detection\n",
    "from util.misc import rescale_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93f637d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:11.349581Z",
     "iopub.status.busy": "2023-07-14T14:37:11.349473Z",
     "iopub.status.idle": "2023-07-14T14:37:11.355334Z",
     "shell.execute_reply": "2023-07-14T14:37:11.354489Z",
     "shell.execute_reply.started": "2023-07-14T14:37:11.349553Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_to_file(contours, file_path):\n",
    "    # according to total-text evaluation method, output file shoud be formatted to: y0,x0, ..... yn,xn\n",
    "    with open(file_path, 'w') as f:\n",
    "        for cont in contours:\n",
    "            cont = np.stack([cont[:, 1], cont[:, 0]], 1)\n",
    "            cont = cont.flatten().astype(str).tolist()\n",
    "            cont = ','.join(cont)\n",
    "            f.write(cont + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc45df56-c393-4e0e-ab2a-7a1b69e37b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:11.356831Z",
     "iopub.status.busy": "2023-07-14T14:37:11.356560Z",
     "iopub.status.idle": "2023-07-14T14:37:11.371532Z",
     "shell.execute_reply": "2023-07-14T14:37:11.370110Z",
     "shell.execute_reply.started": "2023-07-14T14:37:11.356804Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(detector, test_loader, output_dir):\n",
    "    total_time = 0.\n",
    "\n",
    "    for i, (image, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map, meta) in enumerate(test_loader):\n",
    "\n",
    "        image, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map = to_device(\n",
    "            image, train_mask, tr_mask, tcl_mask, radius_map, sin_map, cos_map)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        idx = 0 # test mode can only run with batch_size == 1\n",
    "\n",
    "        # get detection result\n",
    "        contours, output = detector.detect(image)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        total_time += end - start\n",
    "        fps = (i + 1) / total_time\n",
    "        print('detect {} / {} images: {}. ({:.2f} fps)'.format(i + 1, len(test_loader), meta['image_id'][idx], fps))\n",
    "\n",
    "        # visualization\n",
    "        tr_pred, tcl_pred = output['tr'], output['tcl']\n",
    "        img_show = image[idx].permute(1, 2, 0).cpu().numpy()\n",
    "        img_show = ((img_show * cfg['stds'] + cfg['means']) * 255).astype(np.uint8)\n",
    "\n",
    "        pred_vis = visualize_detection(img_show, contours, tr_pred[1], tcl_pred[1])\n",
    "        gt_contour = []\n",
    "        for annot, n_annot in zip(meta['annotation'][idx], meta['n_annotation'][idx]):\n",
    "            if n_annot.item() > 0:\n",
    "                gt_contour.append(annot[:n_annot].int().cpu().numpy())\n",
    "        gt_vis = visualize_detection(img_show, gt_contour, tr_mask[idx].cpu().numpy(), tcl_mask[idx].cpu().numpy())\n",
    "        im_vis = np.concatenate([pred_vis, gt_vis], axis=0)\n",
    "        path = os.path.join(cfg['vis_dir'], '{}_test'.format(cfg['exp_name']), meta['image_id'][idx])\n",
    "        cv2.imwrite(path, im_vis)\n",
    "\n",
    "        H, W = meta['Height'][idx].item(), meta['Width'][idx].item()\n",
    "        img_show, contours = rescale_result(img_show, contours, H, W)\n",
    "\n",
    "        # write to file\n",
    "        mkdirs(output_dir)\n",
    "        write_to_file(contours, os.path.join(output_dir, meta['image_id'][idx].replace('jpg', 'txt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29d6442-a7b8-4837-b3cf-ba1dc53ef042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:12.461509Z",
     "iopub.status.busy": "2023-07-14T14:37:12.459875Z",
     "iopub.status.idle": "2023-07-14T14:37:12.470586Z",
     "shell.execute_reply": "2023-07-14T14:37:12.469807Z",
     "shell.execute_reply.started": "2023-07-14T14:37:12.461509Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if multiprocessing.get_start_method(allow_none=True) is None:\n",
    "        multiprocessing.set_start_method('spawn')\n",
    "    testset = TotalText(\n",
    "        data_root='data/total-text',\n",
    "        ignore_list=None,\n",
    "        is_training=False,\n",
    "        transform=BaseTransform(size=cfg['input_size'], mean=cfg['means'], std=cfg['stds'])\n",
    "    )\n",
    "    test_loader = data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=cfg['num_workers'])\n",
    "\n",
    "    # Model\n",
    "    model = TextNet(is_training=False, backbone=cfg['net'])\n",
    "    model_path = os.path.join(cfg['save_dir'], f\"{cfg['exp_name']}/textsnake_{model.backbone_name}_{cfg['checkepoch']}.pth\")\n",
    "    load_model(model,model_path)\n",
    "\n",
    "    # copy to cuda\n",
    "    model = model.to(cfg['device'])\n",
    "    if cfg['cuda']:\n",
    "        cudnn.benchmark = True\n",
    "    detector = TextDetector(model, tr_thresh=cfg['tr_thresh'], tcl_thresh=cfg['tcl_thresh'])\n",
    "\n",
    "    print('Start testing TextSnake.')\n",
    "    output_dir = os.path.join(cfg['output_dir'], cfg['exp_name'])\n",
    "    inference(detector, test_loader, output_dir)\n",
    "\n",
    "    # compute DetEval\n",
    "    print('Computing DetEval in {}/{}'.format(cfg['output_dir'], cfg['exp_name']))\n",
    "    subprocess.call(['python', 'dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py', args.exp_name, '--tr', '0.6', '--tp', '0.4'])\n",
    "    subprocess.call(['python', 'dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py', args.exp_name, '--tr', '0.8', '--tp', '0.4'])\n",
    "    print('End.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "063279c3-490d-47aa-aff0-79b14ad3c22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T14:37:15.571809Z",
     "iopub.status.busy": "2023-07-14T14:37:15.571419Z",
     "iopub.status.idle": "2023-07-14T14:39:24.867455Z",
     "shell.execute_reply": "2023-07-14T14:39:24.866150Z",
     "shell.execute_reply.started": "2023-07-14T14:37:15.571780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total-text\n",
      "==========Options============\n",
      "A: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
      "B: [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
      "D: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
      "E: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
      "exp_name: vgg123456\n",
      "net: vgg\n",
      "dataset: total-text\n",
      "resume: None\n",
      "num_workers: 8\n",
      "cuda: True\n",
      "mgpu: False\n",
      "save_dir: ./save/\n",
      "vis_dir: ./vis/\n",
      "log_dir: ./logs/\n",
      "loss: CrossEntropyLoss\n",
      "input_channel: 1\n",
      "pretrain: False\n",
      "verbose: True\n",
      "viz: False\n",
      "start_iter: 0\n",
      "max_epoch: 201\n",
      "start_epoch: 0\n",
      "lr: 0.0001\n",
      "lr_adjust: fix\n",
      "stepvalues: []\n",
      "weight_decay: 0.0\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "batch_size: 4\n",
      "optim: SGD\n",
      "display_freq: 50\n",
      "viz_freq: 50\n",
      "save_freq: 50\n",
      "log_freq: 100\n",
      "val_freq: 100\n",
      "rescale: 255.0\n",
      "means: (0.485, 0.456, 0.406)\n",
      "stds: (0.229, 0.224, 0.225)\n",
      "input_size: 512\n",
      "data_root: data/total-text\n",
      "data_custom: False\n",
      "checkepoch: 200\n",
      "img_root: None\n",
      "device: cuda\n",
      "=============End=============\n",
      "Loading from ./save/vgg123456/textsnake_vgg_200.pth\n",
      "Start testing TextSnake.\n",
      "detect 1 / 300 images: img541.jpg. (1.38 fps)\n",
      "detect 2 / 300 images: img619.jpg. (2.54 fps)\n",
      "detect 3 / 300 images: img1547.jpg. (3.59 fps)\n",
      "detect 4 / 300 images: img584.jpg. (4.46 fps)\n",
      "detect 5 / 300 images: img93.jpg. (5.29 fps)\n",
      "detect 6 / 300 images: img994.jpg. (6.10 fps)\n",
      "detect 7 / 300 images: img1191.jpg. (6.81 fps)\n",
      "detect 8 / 300 images: img1544.jpg. (7.45 fps)\n",
      "detect 9 / 300 images: img646.jpg. (8.01 fps)\n",
      "detect 10 / 300 images: img893.jpg. (7.79 fps)\n",
      "detect 11 / 300 images: img634.jpg. (8.32 fps)\n",
      "detect 12 / 300 images: img669.jpg. (8.78 fps)\n",
      "detect 13 / 300 images: img1095.jpg. (9.15 fps)\n",
      "detect 14 / 300 images: img617.jpg. (9.42 fps)\n",
      "detect 15 / 300 images: img5.jpg. (9.87 fps)\n",
      "detect 16 / 300 images: img585.jpg. (10.25 fps)\n",
      "detect 17 / 300 images: img643.jpg. (9.92 fps)\n",
      "detect 18 / 300 images: img676.jpg. (10.17 fps)\n",
      "detect 19 / 300 images: img568.jpg. (10.48 fps)\n",
      "detect 20 / 300 images: img587.jpg. (10.71 fps)\n",
      "detect 21 / 300 images: img649.jpg. (10.80 fps)\n",
      "detect 22 / 300 images: img1198.jpg. (11.11 fps)\n",
      "detect 23 / 300 images: img294.jpg. (11.44 fps)\n",
      "detect 24 / 300 images: img548.jpg. (11.69 fps)\n",
      "detect 25 / 300 images: img598.jpg. (11.92 fps)\n",
      "detect 26 / 300 images: img1394.jpg. (12.18 fps)\n",
      "detect 27 / 300 images: img602.jpg. (12.19 fps)\n",
      "detect 28 / 300 images: img1094.jpg. (12.42 fps)\n",
      "detect 29 / 300 images: img667.jpg. (12.72 fps)\n",
      "detect 30 / 300 images: img193.jpg. (12.90 fps)\n",
      "detect 31 / 300 images: img544.jpg. (13.10 fps)\n",
      "detect 32 / 300 images: img566.jpg. (13.23 fps)\n",
      "detect 33 / 300 images: img1348.jpg. (13.37 fps)\n",
      "detect 34 / 300 images: img200.jpg. (13.51 fps)\n",
      "detect 35 / 300 images: img1540.jpg. (13.68 fps)\n",
      "detect 36 / 300 images: img393.jpg. (13.58 fps)\n",
      "detect 37 / 300 images: img554.jpg. (13.66 fps)\n",
      "detect 38 / 300 images: img610.jpg. (13.83 fps)\n",
      "detect 39 / 300 images: img572.jpg. (13.89 fps)\n",
      "detect 40 / 300 images: img674.jpg. (13.96 fps)\n",
      "detect 41 / 300 images: img998.jpg. (13.84 fps)\n",
      "detect 42 / 300 images: img7.jpg. (13.99 fps)\n",
      "detect 43 / 300 images: img1553.jpg. (13.89 fps)\n",
      "detect 44 / 300 images: img575.jpg. (14.06 fps)\n",
      "detect 45 / 300 images: img612.jpg. (14.17 fps)\n",
      "detect 46 / 300 images: img657.jpg. (14.31 fps)\n",
      "detect 47 / 300 images: img992.jpg. (14.45 fps)\n",
      "detect 48 / 300 images: img1395.jpg. (14.46 fps)\n",
      "detect 49 / 300 images: img583.jpg. (14.52 fps)\n",
      "detect 50 / 300 images: img629.jpg. (14.55 fps)\n",
      "detect 51 / 300 images: img797.jpg. (14.68 fps)\n",
      "detect 52 / 300 images: img1393.jpg. (14.68 fps)\n",
      "detect 53 / 300 images: img635.jpg. (14.64 fps)\n",
      "detect 54 / 300 images: img593.jpg. (14.73 fps)\n",
      "detect 55 / 300 images: img603.jpg. (14.85 fps)\n",
      "detect 56 / 300 images: img1296.jpg. (14.81 fps)\n",
      "detect 57 / 300 images: img642.jpg. (14.85 fps)\n",
      "detect 58 / 300 images: img1396.jpg. (14.88 fps)\n",
      "detect 59 / 300 images: img398.jpg. (14.90 fps)\n",
      "detect 60 / 300 images: img627.jpg. (14.94 fps)\n",
      "detect 61 / 300 images: img618.jpg. (14.95 fps)\n",
      "detect 62 / 300 images: img100.jpg. (15.07 fps)\n",
      "detect 63 / 300 images: img565.jpg. (15.16 fps)\n",
      "detect 64 / 300 images: img92.jpg. (15.23 fps)\n",
      "detect 65 / 300 images: img1291.jpg. (15.35 fps)\n",
      "detect 66 / 300 images: img624.jpg. (15.41 fps)\n",
      "detect 67 / 300 images: img582.jpg. (15.50 fps)\n",
      "detect 68 / 300 images: img655.jpg. (15.58 fps)\n",
      "detect 69 / 300 images: img533.jpg. (15.62 fps)\n",
      "detect 70 / 300 images: img570.jpg. (15.68 fps)\n",
      "detect 71 / 300 images: img588.jpg. (15.76 fps)\n",
      "detect 72 / 300 images: img399.jpg. (15.85 fps)\n",
      "detect 73 / 300 images: img559.jpg. (15.77 fps)\n",
      "detect 74 / 300 images: img898.jpg. (15.79 fps)\n",
      "detect 75 / 300 images: img800.jpg. (15.84 fps)\n",
      "detect 76 / 300 images: img538.jpg. (15.92 fps)\n",
      "detect 77 / 300 images: img1295.jpg. (15.99 fps)\n",
      "detect 78 / 300 images: img1292.jpg. (15.97 fps)\n",
      "detect 79 / 300 images: img658.jpg. (16.00 fps)\n",
      "detect 80 / 300 images: img91.jpg. (16.07 fps)\n",
      "detect 81 / 300 images: img633.jpg. (16.14 fps)\n",
      "detect 82 / 300 images: img993.jpg. (15.96 fps)\n",
      "detect 83 / 300 images: img1398.jpg. (16.02 fps)\n",
      "detect 84 / 300 images: img616.jpg. (16.05 fps)\n",
      "detect 85 / 300 images: img391.jpg. (16.13 fps)\n",
      "detect 86 / 300 images: img794.jpg. (16.21 fps)\n",
      "detect 87 / 300 images: img615.jpg. (16.22 fps)\n",
      "detect 88 / 300 images: img607.jpg. (16.28 fps)\n",
      "detect 89 / 300 images: img295.jpg. (16.26 fps)\n",
      "detect 90 / 300 images: img539.jpg. (16.34 fps)\n",
      "detect 91 / 300 images: img637.jpg. (16.40 fps)\n",
      "detect 92 / 300 images: img540.jpg. (16.18 fps)\n",
      "detect 93 / 300 images: img1299.jpg. (16.21 fps)\n",
      "detect 94 / 300 images: img647.jpg. (16.26 fps)\n",
      "detect 95 / 300 images: img793.jpg. (16.14 fps)\n",
      "detect 96 / 300 images: img1541.jpg. (16.16 fps)\n",
      "detect 97 / 300 images: img600.jpg. (16.11 fps)\n",
      "detect 98 / 300 images: img534.jpg. (16.16 fps)\n",
      "detect 99 / 300 images: img1098.jpg. (16.14 fps)\n",
      "detect 100 / 300 images: img1197.jpg. (16.17 fps)\n",
      "detect 101 / 300 images: img590.jpg. (16.22 fps)\n",
      "detect 102 / 300 images: img891.jpg. (16.14 fps)\n",
      "detect 103 / 300 images: img652.jpg. (16.17 fps)\n",
      "detect 104 / 300 images: img894.jpg. (16.17 fps)\n",
      "detect 105 / 300 images: img595.jpg. (16.18 fps)\n",
      "detect 106 / 300 images: img1400.jpg. (16.23 fps)\n",
      "detect 107 / 300 images: img604.jpg. (16.29 fps)\n",
      "detect 108 / 300 images: img545.jpg. (16.33 fps)\n",
      "detect 109 / 300 images: img625.jpg. (16.37 fps)\n",
      "detect 110 / 300 images: img677.jpg. (16.43 fps)\n",
      "detect 111 / 300 images: img569.jpg. (16.44 fps)\n",
      "detect 112 / 300 images: img1300.jpg. (16.51 fps)\n",
      "detect 113 / 300 images: img599.jpg. (16.48 fps)\n",
      "detect 114 / 300 images: img3.jpg. (16.51 fps)\n",
      "detect 115 / 300 images: img195.jpg. (16.53 fps)\n",
      "detect 116 / 300 images: img1192.jpg. (16.55 fps)\n",
      "detect 117 / 300 images: img671.jpg. (16.52 fps)\n",
      "detect 118 / 300 images: img497.jpg. (16.49 fps)\n",
      "detect 119 / 300 images: img795.jpg. (16.50 fps)\n",
      "detect 120 / 300 images: img622.jpg. (16.41 fps)\n",
      "detect 121 / 300 images: img1392.jpg. (16.44 fps)\n",
      "detect 122 / 300 images: img552.jpg. (16.47 fps)\n",
      "detect 123 / 300 images: img192.jpg. (16.51 fps)\n",
      "detect 124 / 300 images: img558.jpg. (16.39 fps)\n",
      "detect 125 / 300 images: img1550.jpg. (16.43 fps)\n",
      "detect 126 / 300 images: img395.jpg. (16.42 fps)\n",
      "detect 127 / 300 images: img576.jpg. (16.41 fps)\n",
      "detect 128 / 300 images: img560.jpg. (16.42 fps)\n",
      "detect 129 / 300 images: img1297.jpg. (16.46 fps)\n",
      "detect 130 / 300 images: img198.jpg. (16.51 fps)\n",
      "detect 131 / 300 images: img892.jpg. (16.49 fps)\n",
      "detect 132 / 300 images: img641.jpg. (16.53 fps)\n",
      "detect 133 / 300 images: img549.jpg. (16.48 fps)\n",
      "detect 134 / 300 images: img1546.jpg. (16.49 fps)\n",
      "detect 135 / 300 images: img659.jpg. (16.43 fps)\n",
      "detect 136 / 300 images: img95.jpg. (16.47 fps)\n",
      "detect 137 / 300 images: img596.jpg. (16.50 fps)\n",
      "detect 138 / 300 images: img494.jpg. (16.53 fps)\n",
      "detect 139 / 300 images: img96.jpg. (16.47 fps)\n",
      "detect 140 / 300 images: img1097.jpg. (16.46 fps)\n",
      "detect 141 / 300 images: img1092.jpg. (16.39 fps)\n",
      "detect 142 / 300 images: img555.jpg. (16.42 fps)\n",
      "detect 143 / 300 images: img614.jpg. (16.42 fps)\n",
      "detect 144 / 300 images: img609.jpg. (16.38 fps)\n",
      "detect 145 / 300 images: img651.jpg. (16.23 fps)\n",
      "detect 146 / 300 images: img798.jpg. (16.26 fps)\n",
      "detect 147 / 300 images: img866.jpg. (16.29 fps)\n",
      "detect 148 / 300 images: img630.jpg. (16.32 fps)\n",
      "detect 149 / 300 images: img291.jpg. (16.35 fps)\n",
      "detect 150 / 300 images: img298.jpg. (16.39 fps)\n",
      "detect 151 / 300 images: img1093.jpg. (16.37 fps)\n",
      "detect 152 / 300 images: img897.jpg. (16.39 fps)\n",
      "detect 153 / 300 images: img551.jpg. (16.39 fps)\n",
      "detect 154 / 300 images: img999.jpg. (16.41 fps)\n",
      "detect 155 / 300 images: img574.jpg. (16.38 fps)\n",
      "detect 156 / 300 images: img1055.jpg. (16.40 fps)\n",
      "detect 157 / 300 images: img498.jpg. (16.43 fps)\n",
      "detect 158 / 300 images: img1555.jpg. (16.47 fps)\n",
      "detect 159 / 300 images: img899.jpg. (16.51 fps)\n",
      "detect 160 / 300 images: img660.jpg. (16.55 fps)\n",
      "detect 161 / 300 images: img397.jpg. (16.57 fps)\n",
      "detect 162 / 300 images: img293.jpg. (16.61 fps)\n",
      "detect 163 / 300 images: img670.jpg. (16.60 fps)\n",
      "detect 164 / 300 images: img577.jpg. (16.62 fps)\n",
      "detect 165 / 300 images: img903.jpg. (16.60 fps)\n",
      "detect 166 / 300 images: img94.jpg. (16.62 fps)\n",
      "detect 167 / 300 images: img644.jpg. (16.64 fps)\n",
      "detect 168 / 300 images: img611.jpg. (16.66 fps)\n",
      "detect 169 / 300 images: img556.jpg. (16.66 fps)\n",
      "detect 170 / 300 images: img400.jpg. (16.66 fps)\n",
      "detect 171 / 300 images: img594.jpg. (16.67 fps)\n",
      "detect 172 / 300 images: img900.jpg. (16.72 fps)\n",
      "detect 173 / 300 images: img1.jpg. (16.77 fps)\n",
      "detect 174 / 300 images: img542.jpg. (16.80 fps)\n",
      "detect 175 / 300 images: img623.jpg. (16.80 fps)\n",
      "detect 176 / 300 images: img1554.jpg. (16.83 fps)\n",
      "detect 177 / 300 images: img638.jpg. (16.86 fps)\n",
      "detect 178 / 300 images: img561.jpg. (16.83 fps)\n",
      "detect 179 / 300 images: img194.jpg. (16.78 fps)\n",
      "detect 180 / 300 images: img620.jpg. (16.80 fps)\n",
      "detect 181 / 300 images: img586.jpg. (16.82 fps)\n",
      "detect 182 / 300 images: img537.jpg. (16.84 fps)\n",
      "detect 183 / 300 images: img1294.jpg. (16.81 fps)\n",
      "detect 184 / 300 images: img1298.jpg. (16.81 fps)\n",
      "detect 185 / 300 images: img199.jpg. (16.80 fps)\n",
      "detect 186 / 300 images: img1552.jpg. (16.74 fps)\n",
      "detect 187 / 300 images: img601.jpg. (16.77 fps)\n",
      "detect 188 / 300 images: img613.jpg. (16.79 fps)\n",
      "detect 189 / 300 images: img1091.jpg. (16.82 fps)\n",
      "detect 190 / 300 images: img605.jpg. (16.81 fps)\n",
      "detect 191 / 300 images: img535.jpg. (16.82 fps)\n",
      "detect 192 / 300 images: img500.jpg. (16.82 fps)\n",
      "detect 193 / 300 images: img1391.jpg. (16.83 fps)\n",
      "detect 194 / 300 images: img591.jpg. (16.85 fps)\n",
      "detect 195 / 300 images: img567.jpg. (16.86 fps)\n",
      "detect 196 / 300 images: img196.jpg. (16.88 fps)\n",
      "detect 197 / 300 images: img99.jpg. (16.92 fps)\n",
      "detect 198 / 300 images: img661.jpg. (16.90 fps)\n",
      "detect 199 / 300 images: img581.jpg. (16.92 fps)\n",
      "detect 200 / 300 images: img579.jpg. (16.91 fps)\n",
      "detect 201 / 300 images: img10.jpg. (16.94 fps)\n",
      "detect 202 / 300 images: img296.jpg. (16.96 fps)\n",
      "detect 203 / 300 images: img639.jpg. (16.95 fps)\n",
      "detect 204 / 300 images: img1193.jpg. (16.96 fps)\n",
      "detect 205 / 300 images: img496.jpg. (16.99 fps)\n",
      "detect 206 / 300 images: img672.jpg. (16.93 fps)\n",
      "detect 207 / 300 images: img632.jpg. (16.94 fps)\n",
      "detect 208 / 300 images: img995.jpg. (16.94 fps)\n",
      "detect 209 / 300 images: img2.jpg. (16.95 fps)\n",
      "detect 210 / 300 images: img550.jpg. (16.97 fps)\n",
      "detect 211 / 300 images: img668.jpg. (16.97 fps)\n",
      "detect 212 / 300 images: img299.jpg. (17.00 fps)\n",
      "detect 213 / 300 images: img896.jpg. (17.02 fps)\n",
      "detect 214 / 300 images: img394.jpg. (17.02 fps)\n",
      "detect 215 / 300 images: img1539.jpg. (17.04 fps)\n",
      "detect 216 / 300 images: img300.jpg. (17.07 fps)\n",
      "detect 217 / 300 images: img191.jpg. (17.07 fps)\n",
      "detect 218 / 300 images: img1397.jpg. (17.07 fps)\n",
      "detect 219 / 300 images: img664.jpg. (17.02 fps)\n",
      "detect 220 / 300 images: img640.jpg. (17.03 fps)\n",
      "detect 221 / 300 images: img675.jpg. (17.02 fps)\n",
      "detect 222 / 300 images: img97.jpg. (17.04 fps)\n",
      "detect 223 / 300 images: img650.jpg. (17.04 fps)\n",
      "detect 224 / 300 images: img791.jpg. (16.94 fps)\n",
      "detect 225 / 300 images: img492.jpg. (16.97 fps)\n",
      "detect 226 / 300 images: img679.jpg. (16.99 fps)\n",
      "detect 227 / 300 images: img563.jpg. (17.02 fps)\n",
      "detect 228 / 300 images: img493.jpg. (17.04 fps)\n",
      "detect 229 / 300 images: img626.jpg. (17.02 fps)\n",
      "detect 230 / 300 images: img1100.jpg. (16.99 fps)\n",
      "detect 231 / 300 images: img580.jpg. (17.00 fps)\n",
      "detect 232 / 300 images: img1543.jpg. (17.00 fps)\n",
      "detect 233 / 300 images: img543.jpg. (16.99 fps)\n",
      "detect 234 / 300 images: img654.jpg. (16.98 fps)\n",
      "detect 235 / 300 images: img1549.jpg. (16.89 fps)\n",
      "detect 236 / 300 images: img1000.jpg. (16.89 fps)\n",
      "detect 237 / 300 images: img573.jpg. (16.88 fps)\n",
      "detect 238 / 300 images: img663.jpg. (16.85 fps)\n",
      "detect 239 / 300 images: img396.jpg. (16.87 fps)\n",
      "detect 240 / 300 images: img1542.jpg. (16.90 fps)\n",
      "detect 241 / 300 images: img392.jpg. (16.90 fps)\n",
      "detect 242 / 300 images: img796.jpg. (16.92 fps)\n",
      "detect 243 / 300 images: img621.jpg. (16.92 fps)\n",
      "detect 244 / 300 images: img631.jpg. (16.93 fps)\n",
      "detect 245 / 300 images: img997.jpg. (16.94 fps)\n",
      "detect 246 / 300 images: img628.jpg. (16.95 fps)\n",
      "detect 247 / 300 images: img297.jpg. (16.96 fps)\n",
      "detect 248 / 300 images: img895.jpg. (16.98 fps)\n",
      "detect 249 / 300 images: img645.jpg. (17.01 fps)\n",
      "detect 250 / 300 images: img546.jpg. (17.02 fps)\n",
      "detect 251 / 300 images: img197.jpg. (17.05 fps)\n",
      "detect 252 / 300 images: img996.jpg. (17.06 fps)\n",
      "detect 253 / 300 images: img557.jpg. (17.05 fps)\n",
      "detect 254 / 300 images: img1548.jpg. (17.04 fps)\n",
      "detect 255 / 300 images: img1399.jpg. (17.06 fps)\n",
      "detect 256 / 300 images: img592.jpg. (17.07 fps)\n",
      "detect 257 / 300 images: img991.jpg. (17.07 fps)\n",
      "detect 258 / 300 images: img792.jpg. (17.07 fps)\n",
      "detect 259 / 300 images: img578.jpg. (17.09 fps)\n",
      "detect 260 / 300 images: img1194.jpg. (17.11 fps)\n",
      "detect 261 / 300 images: img1200.jpg. (17.12 fps)\n",
      "detect 262 / 300 images: img589.jpg. (17.14 fps)\n",
      "detect 263 / 300 images: img8.jpg. (17.14 fps)\n",
      "detect 264 / 300 images: img1099.jpg. (17.15 fps)\n",
      "detect 265 / 300 images: img606.jpg. (17.14 fps)\n",
      "detect 266 / 300 images: img1196.jpg. (17.14 fps)\n",
      "detect 267 / 300 images: img662.jpg. (17.14 fps)\n",
      "detect 268 / 300 images: img1195.jpg. (17.14 fps)\n",
      "detect 269 / 300 images: img4.jpg. (17.14 fps)\n",
      "detect 270 / 300 images: img9.jpg. (17.16 fps)\n",
      "detect 271 / 300 images: img608.jpg. (17.15 fps)\n",
      "detect 272 / 300 images: img491.jpg. (17.16 fps)\n",
      "detect 273 / 300 images: img1551.jpg. (17.18 fps)\n",
      "detect 274 / 300 images: img292.jpg. (17.20 fps)\n",
      "detect 275 / 300 images: img597.jpg. (17.20 fps)\n",
      "detect 276 / 300 images: img536.jpg. (17.23 fps)\n",
      "detect 277 / 300 images: img666.jpg. (17.23 fps)\n",
      "detect 278 / 300 images: img665.jpg. (17.25 fps)\n",
      "detect 279 / 300 images: img1199.jpg. (17.27 fps)\n",
      "detect 280 / 300 images: img1096.jpg. (17.22 fps)\n",
      "detect 281 / 300 images: img553.jpg. (17.22 fps)\n",
      "detect 282 / 300 images: img648.jpg. (17.22 fps)\n",
      "detect 283 / 300 images: img562.jpg. (17.23 fps)\n",
      "detect 284 / 300 images: img547.jpg. (17.17 fps)\n",
      "detect 285 / 300 images: img636.jpg. (17.17 fps)\n",
      "detect 286 / 300 images: img564.jpg. (17.14 fps)\n",
      "detect 287 / 300 images: img656.jpg. (17.13 fps)\n",
      "detect 288 / 300 images: img6.jpg. (17.12 fps)\n",
      "detect 289 / 300 images: img673.jpg. (17.12 fps)\n",
      "detect 290 / 300 images: img532.jpg. (17.14 fps)\n",
      "detect 291 / 300 images: img571.jpg. (17.14 fps)\n",
      "detect 292 / 300 images: img495.jpg. (17.15 fps)\n",
      "detect 293 / 300 images: img499.jpg. (17.15 fps)\n",
      "detect 294 / 300 images: img98.jpg. (17.17 fps)\n",
      "detect 295 / 300 images: img531.jpg. (17.16 fps)\n",
      "detect 296 / 300 images: img678.jpg. (17.16 fps)\n",
      "detect 297 / 300 images: img653.jpg. (17.17 fps)\n",
      "detect 298 / 300 images: img1293.jpg. (17.18 fps)\n",
      "detect 299 / 300 images: img799.jpg. (17.19 fps)\n",
      "detect 300 / 300 images: img1545.jpg. (17.21 fps)\n",
      "Computing DetEval in ./output//vgg123456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      " 12%|█▏        | 36/301 [00:05<00:25, 10.57it/s]/notebooks/dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py:78: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if (gt[5] == '#') and (gt[1].shape[1] > 1):\n",
      "/notebooks/dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py:134: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  dc_id = np.where(groundtruths[:, 5] == '#')\n",
      "100%|██████████| 301/301 [00:42<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped directory .ipynb_checkpoints\n",
      "Input: output/vgg123456\n",
      "Config: tr: 0.6 - tp: 0.4\n",
      "Precision = 0.8367 - Recall = 0.6616 - Fscore = 0.7389\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      " 12%|█▏        | 36/301 [00:04<00:24, 10.94it/s]/notebooks/dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py:78: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if (gt[5] == '#') and (gt[1].shape[1] > 1):\n",
      "/notebooks/dataset/total_text/Evaluation_Protocol/Python_scripts/Deteval.py:134: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  dc_id = np.where(groundtruths[:, 5] == '#')\n",
      " 99%|█████████▊| 297/301 [00:41<00:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped directory .ipynb_checkpoints\n",
      "Input: output/vgg123456\n",
      "Config: tr: 0.8 - tp: 0.4\n",
      "Precision = 0.7802 - Recall = 0.6244 - Fscore = 0.6937\n",
      "\n",
      "Done.\n",
      "End.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:41<00:00,  7.24it/s]\n"
     ]
    }
   ],
   "source": [
    "option = BaseOptions()\n",
    "\n",
    "command_line_args = [\"vgg123456\", \"--net\", \"vgg\", \"--checkepoch\", \"200\"]  \n",
    "args = option.initialize(command_line_args)\n",
    "\n",
    "update_config(cfg, args)\n",
    "print_config(cfg)\n",
    "\n",
    "vis_dir = os.path.join(cfg['vis_dir'], '{}_test'.format(cfg['exp_name']))\n",
    "if not os.path.exists(vis_dir):\n",
    "    mkdirs(vis_dir)\n",
    "\n",
    "cfg['D'] = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "cfg['tr_thresh'] = 0.6\n",
    "cfg['tcl_thresh'] = 0.4\n",
    "# config['post_process_expand'] = 0.3\n",
    "cfg['output_dir'] = \"./output/\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342839e2-4389-418c-a35c-00f1216c4659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
